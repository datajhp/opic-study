import streamlit as st
import whisper
import tempfile
import torch
import numpy as np
from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, WebRtcMode
import av
import queue

# ëª¨ë¸ ë¡œë”©
@st.cache_resource
def load_whisper():
    return whisper.load_model("base")

@st.cache_resource
def load_grammar_model():
    tokenizer = AutoTokenizer.from_pretrained("vennify/t5-base-grammar-correction")
    model = AutoModelForSeq2SeqLM.from_pretrained("vennify/t5-base-grammar-correction")
    return tokenizer, model

# ë¬¸ë²• í”¼ë“œë°± í•¨ìˆ˜
def grammar_correction(text):
    tokenizer, model = load_grammar_model()
    inputs = tokenizer.encode(text, return_tensors="pt", truncation=True, max_length=512)
    outputs = model.generate(inputs, max_length=512, num_beams=4)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

st.title("ğŸ¤ ì˜¤í”½ ì˜ì–´ ë§í•˜ê¸° ì—°ìŠµ ì•±")

tabs = st.tabs(["ğŸ“ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ™ ë§ˆì´í¬ ë…¹ìŒ", "âœï¸ í…ìŠ¤íŠ¸ ì…ë ¥"])

# 1. í…ìŠ¤íŠ¸ ì…ë ¥ íƒ­
with tabs[2]:
    user_input = st.text_area("ì˜¤í”½ ì‘ë‹µì„ ì˜ì–´ë¡œ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”:", height=150)
    if st.button("âœ… ë¬¸ë²• í”¼ë“œë°± ë°›ê¸°"):
        if user_input.strip() == "":
            st.warning("ë¬¸ì¥ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info("ë¬¸ë²• êµì • ì¤‘ì…ë‹ˆë‹¤...")
            corrected = grammar_correction(user_input)
            st.subheader("âœ… êµì •ëœ ë¬¸ì¥")
            st.success(corrected)

# 2. ìŒì„± íŒŒì¼ ì—…ë¡œë“œ íƒ­
with tabs[0]:
    uploaded = st.file_uploader("ì˜¤í”½ ì‘ë‹µ ìŒì„± íŒŒì¼ ì—…ë¡œë“œ (.wav / .mp3)", type=["wav", "mp3"])
    if uploaded:
        st.audio(uploaded)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp:
            tmp.write(uploaded.read())
            tmp_path = tmp.name

        st.info("ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘ì…ë‹ˆë‹¤...")
        whisper_model = load_whisper()
        result = whisper_model.transcribe(tmp_path)
        user_text = result["text"]
        st.markdown("**ğŸ§ ì „ì‚¬ ê²°ê³¼:**")
        st.write(user_text)

        corrected = grammar_correction(user_text)
        st.markdown("**âœ… êµì •ëœ ë¬¸ì¥:**")
        st.success(corrected)

# 3. ë§ˆì´í¬ ë…¹ìŒ íƒ­
with tabs[1]:
    st.info("ğŸ¤ ë¸Œë¼ìš°ì €ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”!")
    audio_queue = queue.Queue()
    st.write("ğŸ§ ë…¹ìŒëœ í”„ë ˆì„ ìˆ˜:", len(audio_queue.queue))


    class AudioProcessor(AudioProcessorBase):
        def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
            pcm = frame.to_ndarray().flatten().astype(np.float32)
            audio_queue.put(pcm)
            return frame

    webrtc_ctx = webrtc_streamer(
        key="mic",
        mode=WebRtcMode.SENDONLY,
        audio_receiver_size=256,
        media_stream_constraints={"audio": True, "video": False},
        audio_processor_factory=AudioProcessor,
        async_processing=True,
    )

    if st.button("ğŸ¬ ë…¹ìŒ ì¢…ë£Œ í›„ ë¶„ì„"):
        if not audio_queue.empty():
            st.info("ğŸ”„ ìŒì„± ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")

            all_audio = []
            while not audio_queue.empty():
                all_audio.extend(audio_queue.get())
            audio_tensor = torch.tensor(all_audio)
            sample_rate = 48000

            with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
                tmp_audio_path = f.name
                import torchaudio
                torchaudio.save(tmp_audio_path, audio_tensor.unsqueeze(0), sample_rate)

            whisper_model = load_whisper()
            result = whisper_model.transcribe(tmp_audio_path)
            user_text = result["text"]
            st.markdown("**ğŸ§ ì „ì‚¬ ê²°ê³¼:**")
            st.write(user_text)

            corrected = grammar_correction(user_text)
            st.markdown("**âœ… êµì •ëœ ë¬¸ì¥:**")
            st.success(corrected)
        else:
            st.warning("ë…¹ìŒëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
